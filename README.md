


# project Harpia
## Harpia is the Mithological creature responsible to deliver the news and other things.
## Data Exchange and Service Gateway

## objective:
Create a generalized interface for processes and threads to share data among themselves, database and web that has gRPC, ORM, RESTFull, SOAP, CRUDL, multi-project, multi-language and a  multi-thread library to exchange data.

## goals:
* a shared library must be created so that all other projects can use
* this library must be integratable in all languages we support
* all processes must be secure and safe (intrinsecaly secure means it will never fail and safe means that the comunication is going to be secure (SSL))
* versioning must be embedded in the process and in the library.
* Versioning must be transperant for the developer. Old versions must be avialable always for the developers, but resources of other versions may not be interchangable.
* Integration with versioning systems (git) every harpia project if forked from this project.
* data types, created by one project cannot be changed by another project, but it can be inherited by this project classes.
	* languages with function interfaces will have plenty of changes to allow templating.
* data types, of the same project, can be always agregated, but this will impact at the querie level
* data types, of diferent projects are agregated via foreing key. Representation at the database is independent of each other but might have impact in security
* data types can have a separeted representation in the database, even if it is agregated.
* data types that are unique in the database will be allowed.
* functions of database (CRUDL) are always available, but usage may be restricted or non existent.
* functions of RestFull API must be available with other projects (CurL, COW, etc).
* functions to read-once, read-all, read-until, should be implemented.
* events and via callbacks connected to detached threads must be implemented.
	* create, change, update. Read will not generate new events
 * database is implemented securelly - always
* all classes MUST HAVE A toString method. 
	* toString must be overloaded 
		- pretty print (json like)
		- pretty print (xml like)
		- pretty print (yaml like)
* constants must be represented
* initialization of variables must be allowed all constants must be initialized

## process
# creation of a specialized proto file. 
This protofile will have special tags in it that will enable and configure each feature.
User authentication must be implemented in the following fashion:
* database protection and roles.
	* admin user (administrative role) 
		* will be responsible to create, backup, delete, clear, and all tasks related with mantaining the application
		* it can not access the data, but can add users and change roles
  		* users created by this admin cannot create other users for this database, but users created by this database could create other databases
	* main user (cannot change the database, but can add, remove and query registers)
		* regular user of the data in the database. Systems that do not require this, are going to have the admin user as the main user.
		* it cannot add a new column, but can add a number of registries
	* guest user (cannot change the database, but can query)
		* user shared around. Systems that do not require this will have the guest user as the main user.
* access to data must have session keeping
	* user authentication happens once on the begining of a session and no longer necessary
 		** implementation depends on database **
	* restart of one application will require a new authentication
	* Guest User authentication happens automaticaly, Main user authentication happens with embedded key (generated by versioning)
	* one session is guaranteed to exist and no password will be required. 
		* the session ends when another session is started with the same password or if keep-alive no longer blips
	* criptography is an option: 
		* criptography is an option that is discourage. It is embedded systems.
* acess to streamming and public variables:
	* public and available information.
	* no video streamming is available. 
# Access to information can happen via 3 main avenues:
* RPC (Remote Procedure Call)
	* the data is returned as soon as the procedure is finished via a response (data is returned to the caller)
		* the function can be blocking or non-blocking
			* blocking function can have a timeout or no timeout
				* timeout can be programmable or configurable, but return code when the function times out is always configurable
				* configuration of the return code must allow for null, nil or equivalent.
     		* non-blocking function will have a self generated callback that is not detached (???)
* a callback 
	* a callback is called as a detached thread with a try-catch. It is launched with the user function as a callback - errors are reported outside of the scope of the remote entity
 	* variables that must be captured (lambda for C++ or other types of data capturing) should be impplemented by the user. paramenter of the callback is the return of the query and will be relative to the design of the user. So, if a query returns a set of hundreds of thousands of registers, user will crash the system eventualy. Protection against this is embedded on the system and must be standartized - a known maximum number of registers will be returned.
  	* callbacks parameter (return of the querie and or RestFULL api) should be implemented by us and not the end user.
* a stream - data is sent continuously via a read like function that will return information regarding the producer. 
	* it is very close to a hardware interface for linux.
		* has a setup function that you can pass the configurations and can return IN-VALID
		* a read function that return the data as configured, it will return null, nill or something to that effect (configurable)
			* can be blocking or non-blocking, but it is always timed (a configurable timeout feature is possible, but a timeout is passed via read function.)
		* a stop functon that will kill the connection. If stop function was not called in a configurable amount of time, the connection is killed and "read" function must return IN-VALID
  		* upon deletion of object, all the resources must be available back to the system. 
	* dead connections or connection that are not kept alive will be reclaimed by the system.
Data types are directly enabled to be shared via other protocols, such as HTTP:
* RestFULL api will be generated with the names of the variables as URLÂ´s.
	* GET, PUT, PATCH, DELETE must be implemented.
 		* GET can return all variables, and the protocol (json, yaml, SOAP or other) is responsible to determine that.
   		* PUT will replace the entyre registry and/or internal variable. If it is not properly set, it must return an error
     		* PATCH will replace only the parts of the registry, if a register is found. Will return error otherwise. Complete update of a variable is possibel, however, this must exist with a warning that will consume more resources.
       		* DELETE will delete the entry on database and/or delete the data in use
* serialization of the data into json, yaml, xml
* interfaces to RestFull API must be available (/name_of_project/version/name_of_message/)
* data must have SOAP - autogenerated (XML with the definition for getting and setting data)
Databases are part of the environment.
The environment requires at least one database for all the projects within this environment. The public database will always be available to every one. But the private will only be available by the creator of the library.
*************************************************************************************************
## proto definition
PROTO files are files that define varibles, have tags that describe how this variables will be accessed and names that will define how the variables will be stored.
normal PROTO message:
> enum <name>{
	<enum-name> = 0;
	<enum-name> = 1;
}
message <name>{
	<modifier> <var_type> <var_name>;
	<enum_type>:<value> <var_name>;
}

### where:
* <name> is the name of the message/enum and only one is possible per file.
* <modifier> is prefix for that variable (repeteable, optional, constant, etc ).
	* * constant modifier must have a initializer value. If no value is defined after the variable type (with the colon ":"), no function to change this variable will be provided and this variable will only be set with constructor.
	* * 
* <var_type> is the time of the variable and could be a simple type such as "string", "int", "float", etc, or a complex type, such as the type defined by another message. <var_type> cannot have circular references.
* <var_name> is the name of the variable and must created following the coding standart and cannot repeat
* !!!! <index> is the position of the variable inside the structure. No two indexes can be equal and must begin with 1, this is generated automaticaly and it is not the same as enum numbers.!!!!
* <enum_type>:<value> is a variable created from the enum_type inicialized with <value>
* basic values (int, char, string, enum) are inserted simplistic after the colon other types are inserted with brackets and ordered by comas in the same other they were created (all variables must be present including the optional ones). The random is key word that can be used instead of the value to generate a random variable.
now, for this development
><access_modifier>[...] message <name> {
	int id;
	<modifier>[...] <type/message_name> <var_name>[<regex>]; //comment
}<table_name>;
### where:
* <access_modifier>[...] are the modifiers available to access this information. It is possible to have multiple <access_modifier>, but it is not possible to change the behavior of the <access_modifier>. To change the behavior of the modifier, it is necessary to create a new modifier, with a new name.
	- stream - this modifier tells us that there will be a stream available for this information
		stream[#] contains the amount of data that will be streammed or until it is available by the writer
		streams cannot be cached (held in memory)
	- event[cached/not-cached] - events are OnChange events on the data_type. Cached messages always returns the last available data as soon as the connection starts. On the otherhand not-cached messages will only return if the changes happens after the connection.
		events are not streammed. 
	- pull - pullaeble messages are the ones that can be read from the database or as RPC immediatly from anyone, either public or private databases. This represents a relationship of one-to-many
	There are several interfaces to pull a message:
		* every variable can serve as a filter for a query
		* every Foreing-Key can be used as filter for a query
	* * multiple <access_modifier> does not means multiple features in one type of access, but it does mean multiple access created for this variable.
	- push - pushable messages are those who can be pushed from everyone. So anyone inside the network can push data into this variable. This is a automatic many-to-one relationship.
		
	- pushpull - are variables that can be published by anyone and pulled by anyone (this is the standard behavior). This represents a many-to-many relationship.

* <name> -- must be defined according with the standart coding of the company and must not be equal to any other message on this file, and no internal variable can be equal to this name.
* int id = 1; -- is OBRIGATORY and always will occupy the first index. It is primary-key for the database when applicable, but always will exist. Index 0 is NOT USABLE and an error should occur in compilation time. 
* <modifier>[...] several modifiers can be concatenated to form the innerworking of a table or a variable
	* optional -- this variable is optional and do not need to be present
	* repeteable -- this variable is dinamically allocated
	   * if it is a database, a new table is created to contain this variable.
	* map -- this means that the variable is a map of a first and a second item.
		* serialization, in this case, will treat the map as a list of dict
			ex.: 
			> message {
					map<string, int> street_number_of_house;
			}
			the serialization will return:
			{street_number_of_house: [{string1,int1},{string2,int2},{string3,int3}...]}
	* repeteable[size] -- this variable is statically allocated by "size". Even if it is a database.
		* 'size' represent the absolute maximum this variable can allocate.
		* a table is created with fixed size
	* pagination -- this means that there are functions related to the pagination of this variable by an amount that is passed via pararmeter
	* pagination[size] - this means that the pagination if fixed in "size" items per page
	* required - this means that this variable is absolutely necessary. It is required in the database and all the functions to set data will have this as parameter.
	* unique - this means that the content of this variable cannot repeat itself in the database.
* <type/message_name> is the type of the variable or the Foreign-Key used to merge 2 messages.
	* as a type, it can be another message, regular simple type available in protobuf meta language
	* as a Foreing-Key, it must be the index of another message, since it always exist, it will always be present. 
* <var_name> is the name of the variable and must created following the coding standart
* [<regex>] -- this is a optional configuration that exist to allow the limits of this variable to be present when defining the variable. For example:
	> message home {
		repeteable[10] char name["^[a-z0-9_\-]+$"];
	}
	this will create a message, with an array of printable characters of max size 10.
* <table_name> is the name of the table that will be created. 
	* if ended with ";" then it is private. The database is public otherwise
	* if a table_name is not present, that means the table is not created.
		* if it is ended with a ";" that mens that this is a private message and only the owner can create/publish data.
		* if it is ended without the ";", that means that this is a public message and every one with access to this library can produce the information. 
			* This will result at a environment where all the projects that includes this module will have the hability to publish information.
	
## Functions created
### CRUDL
* if a table_name is present, than the table must be created.
	* if it ends with a ";", then the table is private
	* if it ends without a ";", then the table is public
	* if it is a table, repeatable variables are represented in the database in another private table
* if a table_name is not present, that means that the table will not be created
   * if it is not a table, repeateble variables are present in memory as arrays, vectors, or lists
### Serialization
 * Serializers provided are intrinscically safe. Never ever they will crash.
 * Memory consumption is limited by the system. If memory is out, serializer returns an error of no memory and a standartized message.
 * map variables are serialized as dicts 
### SOAP
* SOAP is a xml protocol implemented over http

### Documentation in code with examples
All code is documented via doxygen.
All interfaces (HTTP, SOAP, protoduf, gRPC, etc) and methods (c++, C#, java, etc) must have a usage example that must be ran in an Integration Test
All unit tests have to pass to form the code.
Source code generated and library generated will be available to the user to integrate in the project or link in the project

## Level of tests
These tests are not the tests of the code generator, but of the code generated. 
Every single branch of code must be tested. 
Unit Tests are small and have to test functionalities of each variable and each set and get function. All of the access related tests must be implemented here. All thresholds, limits and access mode, must be implemented here.
Functional Tests are medium tests created to check functionalities such as integration with database, serializations, callbacks, gRPC and streams.
Integration Tests are bigger and must be able to test in a docker like environment (we must have a way to execute it "portable") - since we will need to use communication privileges. The idea is to have some sort of process that will use the data for some dummy, but time consuming purpose. 

## Test of the code generator
This tests are only ran if the code generator changes.
all features must be tested. And one example must be created to reach every branch of the code, so, if one feature is a function that is accessed only once and data is destroyed, the test is the generation of that function and test of that function.


# Enablihng/Disabling features
All features and code generation can be independently disabled. If a feature depends on another, it will be executed, but a warning message will appear. 



# Tools
* protobuf gRPC
* cmake
* make
* python 3.10
* bashs

# Configurations
All configurations must be available at the protobuf file.
Configurations related to specific language definitions must be available at the protobuf file.
Should have language selection within the protobuf?

# philosophy
1. every bug create unit tests.
2. all architecture must be available in code after processed via comments
3. all documentation must be available in code after processed (doxigen)













#
